# ========================================================
# requirements_infer_batch.txt
# Environment dependencies for remote server inference
# For the infer_batch.py batch scene generation script
# ========================================================

# ===== Core ML Framework =====
# ms-swift: ModelScope SWIFT framework for model inference
ms-swift>=3.2.0

# PyTorch: Deep learning framework
torch>=2.1.0,<2.8.0

# Transformers: Hugging Face model library
transformers>=4.46.0,<4.60.0

# vLLM: High-performance LLM inference engine (for VllmEngine)
vllm>=0.6.0

# ===== Azure OpenAI =====
# For calling Azure OpenAI API (e.g., GPT-4o for initial scene generation)
openai>=1.0.0
azure-identity>=1.12.0

# ===== Model Support =====
# ModelScope: Model download and management
modelscope>=1.23

# PEFT: Parameter-efficient fine-tuning (LoRA, etc.)
peft>0.11,<0.18

# Qwen VL Utils: Qwen2.5-VL model utilities
qwen_vl_utils==0.0.11

# ===== Physics & 3D Processing =====
# Trimesh: 3D mesh processing (for physics validation and collision detection)
trimesh>=4.0.0

# NumPy: Numerical computing (version capped to avoid compatibility issues)
numpy<2.0.0

# SciPy: Scientific computing (for rotation transforms, etc.)
scipy>=1.10.0

# Shapely: Geometry computation (for polygon collision detection)
shapely>=2.0.0

# ===== Image Processing =====
# Pillow: Image processing
Pillow>=9.0.0

# ===== Distributed Training & Inference =====
# DeepSpeed: Distributed training acceleration
deepspeed>=0.16.0

# Accelerate: Hugging Face distributed training toolkit
accelerate>=0.30.0

# Flash Attention: Efficient attention mechanism (requires CUDA)
# Note: flash-attn needs to be compiled from source or use a pre-built wheel
flash-attn>=2.7.0

# ===== Logging & Monitoring =====
# SwanLab: Experiment tracking
swanlab

# Weights & Biases: Experiment tracking and visualization
wandb

# ===== Utilities =====
# msgspec: High-performance message serialization
msgspec

# Requests: HTTP request library
requests

# PyBind11: C++ bindings (required by some dependencies)
pybind11

# ===== CLIP & Retrieval =====
# open-clip-torch: CLIP model for asset retrieval
open-clip-torch>=2.0.0

# ftfy: Text cleanup for CLIP tokenizer
ftfy

# sentence-transformers: Sentence embeddings for asset retrieval
sentence-transformers

# ===== Compression & Serialization =====
# compress_json: Compressed JSON I/O
compress_json

# compress_pickle: Compressed pickle I/O
compress_pickle

# ===== Physics =====
# python-fcl: FCL collision checking bindings
python-fcl

# ========================================================
# Installation Instructions
# ========================================================
#
# 1. Basic installation:
#    pip install -r requirements_infer_batch.txt
#
# 2. Flash Attention installation (requires CUDA):
#    pip install flash-attn --no-build-isolation
#
# 3. Blender installation (for scene rendering):
#    bash quick_install_blender.sh
#
# 4. Verify installation:
#    python -c "from swift.llm import VllmEngine; print('Swift OK')"
#    python -c "import vllm; print('vLLM OK')"
#    python -c "import torch; print(f'PyTorch OK, CUDA: {torch.cuda.is_available()}')"
#
# ========================================================
# Usage Examples
# ========================================================
#
# Single GPU inference:
#   python infer_batch.py --batch-mode --parallel \
#       --model /path/to/storage/ckpt/rl_v3_2 \
#       --prompts-file /path/to/storage/datasets/llmscene/sft/test_prompt_v2.txt \
#       --iterations 10 --output ./output/batch_results
#
# 4-GPU parallel inference (4x A100):
#   python infer_batch.py --batch-mode --parallel \
#       --model /path/to/storage/ckpt/rl_v3_2 \
#       --tensor-parallel 4 \
#       --max-batch-size 4 \
#       --max-history-turns 4 \
#       --prompts-file /path/to/storage/datasets/llmscene/sft/test_prompt_v2.txt \
#       --iterations 10 --output ./output/batch_results
#
# Using Objaverse assets:
#   python infer_batch.py --batch-mode --parallel \
#       --asset-source objaverse \
#       --model /path/to/storage/ckpt/rl_v3_2 \
#       --prompts-file /path/to/storage/datasets/llmscene/sft/test_prompt_v2.txt
#
# ========================================================
